import csv
import pandas as pd
import streamlit as st
import os
from jobspy import scrape_jobs

st.set_page_config(page_title="Helper", layout="wide")
st.title("üíº Helper ‚Äì Tech/Infra Job Scraper & Filter")

# Function to scrape and filter jobs
def fetch_and_filter_jobs():
    # ‚úÖ Broader search coverage
    search_term_query = (
        "business analyst"
    )

    google_search_term_query = search_term_query

    jobs = scrape_jobs(
        site_name=["linkedin", "indeed", "glassdoor", "google"],
        search_term=search_term_query,
        google_search_term=google_search_term_query,
        location="United States",
        results_wanted=500,
        hours_old=48,
        country_indeed="USA",
        job_type="fulltime",
        linkedin_fetch_description=True,
        verbose=1
    )

    # Save raw data
    jobs.to_csv("all_scraped_jobs.csv", quoting=csv.QUOTE_NONNUMERIC, escapechar="\\", index=False)

    # ‚úÖ Match jobs semantically based on title/description
    job_keywords = [
        "business analyst"
    ]

    jobs_filtered = jobs[
        jobs["title"].str.lower().str.contains("|".join(job_keywords), na=False) |
        jobs["description"].str.lower().str.contains("|".join(job_keywords), na=False)
    ]

    # ‚ùå Exclude jobs with undesirable terms in title/description
    filter_title = [
        'citizenship', 'senior', 'lead', 'sr',
        'clearance', 'secret', 'manager', 'mgr',
        'us citizen', 'principal', 'embedded', 'hvac', 'staff'
    ]
    filter_description = [
        'citizenship', 'clearance', 'secret', 'ts/sci', 'citizen'
    ]

    jobs_filtered = jobs_filtered[~(
        jobs_filtered['title'].str.lower().str.contains('|'.join(filter_title), na=False) |
        jobs_filtered['description'].str.lower().str.contains('|'.join(filter_description), na=False)
    )]

    # Save filtered data
    jobs_filtered.to_csv("tech_infra_jobs_filtered.csv", quoting=csv.QUOTE_NONNUMERIC, escapechar="\\", index=False)

    return jobs_filtered

# Try to load from saved file if it exists
jobs_df = None
if os.path.exists("tech_infra_jobs_filtered.csv"):
    jobs_df = pd.read_csv("tech_infra_jobs_filtered.csv")
    st.success(f"üìÑ Loaded {len(jobs_df)} previously scraped tech/infra jobs from file.")

# Scrape fresh data only when button is clicked
if st.button("üîç Scrape Latest Tech/Infra Jobs"):
    with st.spinner("Scraping and filtering jobs..."):
        jobs_df = fetch_and_filter_jobs()
    st.success(f"‚úÖ Scraped and found {len(jobs_df)} relevant jobs!")

# Display if jobs are available
if jobs_df is not None:
    # Filter toggle
    big_companies_only = st.checkbox("üè¢ Show only jobs from big companies", value=False)

    # Apply big company filter if selected
    display_df = jobs_df.copy()
    if big_companies_only:
        company_counts = display_df["company"].value_counts()
        threshold = company_counts.quantile(0.95)  # Top 5% most frequent
        big_companies = company_counts[company_counts >= threshold].index.tolist()
        display_df = display_df[display_df["company"].isin(big_companies)]
        st.info(f"Showing {len(display_df)} jobs from top-posting companies.")
    else:
        st.info(f"Showing all {len(display_df)} relevant jobs.")

    # Download button
    st.download_button("‚¨áÔ∏è Download CSV", data=display_df.to_csv(index=False), file_name="tech_jobs_filtered.csv")

    # Display table
    columns_to_display = ['title', 'company', 'location', 'job_url', 'date_posted']
    valid_columns = [col for col in columns_to_display if col in display_df.columns]
    st.dataframe(display_df[valid_columns], use_container_width=True)

else:
    st.info("Click the button above to scrape and display the latest jobs.")
